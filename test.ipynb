{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir l'URL de l'API et les en-têtes\n",
    "API_URL = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_definition_and_examples(word):\n",
    "    # prompt \n",
    "    prompt = f\"\"\"\n",
    "        You are an English language assistant. \n",
    "        Provide a JSON with a definition and two examples for the word \"{word}\".\n",
    "        Return ONLY a valid JSON in this format:\n",
    "        {{\n",
    "            \"definition\": \"brief definition here\",\n",
    "            \"examples\": [\"example sentence 1\", \"example sentence 2\"]\n",
    "        }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Préparer la charge utile\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"temperature\": 0.1,  # Réduit pour des réponses plus cohérentes\n",
    "            \"max_new_tokens\": 200,\n",
    "            \"return_full_text\": False  # Ne retourne que le nouveau texte généré\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Envoyer la requête POST\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    \n",
    "    # Vérifier le statut de la réponse\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        generated_text = response_data[0][\"generated_text\"]\n",
    "        \n",
    "        # Déboggage\n",
    "        # print(\"Réponse complète:\", generated_text)\n",
    "        \n",
    "        # Trouver tous les blocs qui ressemblent à du JSON\n",
    "        all_json_candidates = re.findall(r'\\{[^{]*\"definition\"[^{]*\"examples\"[^{]*\\}', generated_text, re.DOTALL)\n",
    "        \n",
    "        # Si des candidats sont trouvés, essayer de les analyser un par un\n",
    "        for json_candidate in all_json_candidates:\n",
    "            try:\n",
    "                # Nettoyer le candidat\n",
    "                clean_json = json_candidate.strip()\n",
    "                # Vérifier s'il y a du texte après la dernière accolade fermante\n",
    "                if not clean_json.endswith('}'):\n",
    "                    clean_json = clean_json[:clean_json.rfind('}')+1]\n",
    "                \n",
    "                # Essayer de parser le JSON\n",
    "                result = json.loads(clean_json)\n",
    "                \n",
    "                # Vérifier que le résultat a la structure attendue\n",
    "                if \"definition\" in result and \"examples\" in result and isinstance(result[\"examples\"], list):\n",
    "                    return result\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        # Si aucun JSON valide n'a été trouvé, essayons d'extraire les informations manuellement\n",
    "        definition_match = re.search(r'\"definition\"\\s*:\\s*\"([^\"]+)\"', generated_text)\n",
    "        examples_match = re.search(r'\"examples\"\\s*:\\s*\\[\\s*\"([^\"]+)\"\\s*,\\s*\"([^\"]+)\"\\s*\\]', generated_text)\n",
    "        \n",
    "        if definition_match and examples_match:\n",
    "            return {\n",
    "                \"definition\": definition_match.group(1),\n",
    "                \"examples\": [examples_match.group(1), examples_match.group(2)]\n",
    "            }\n",
    "        \n",
    "        print(\"Aucun JSON valide trouvé dans la réponse\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Erreur API Hugging Face: {response.status_code} -> {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultat extrait avec succès:\n",
      "Définition: A living organism belonging to the genus Homo and characterized by highly developed intelligence, articulate speech, and a contrarily frail body.\n",
      "Exemples: ['She is a human being, just like you and me.', 'The human being has the ability to create and destroy.']\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "word = \"human being\"\n",
    "result = get_definition_and_examples(word)\n",
    "if result:\n",
    "    print(\"\\nRésultat extrait avec succès:\")\n",
    "    print(\"Définition:\", result[\"definition\"])\n",
    "    print(\"Exemples:\", result[\"examples\"])\n",
    "else:\n",
    "    print(\"Impossible d'obtenir la définition et les exemples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_definition_and_examples(word):\n",
    "    # Structurer le prompt \n",
    "    prompt = f\"\"\"\n",
    "        You are an English language assistant. \n",
    "        Provide a definition, French translation, and two example sentences in English for the English word \"{word}\". \n",
    "        Format your response as JSON with fields: word, definition, translation, example1, example2.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Préparer la charge utile\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"temperature\": 0.1,  # Réduit pour des réponses plus cohérentes\n",
    "            \"max_new_tokens\": 200,\n",
    "            \"return_full_text\": False  # Ne retourne que le nouveau texte généré\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Envoyer la requête POST\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    \n",
    "    # Vérifier le statut de la réponse\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        generated_text = response_data[0][\"generated_text\"]\n",
    "        \n",
    "        if generated_text : \n",
    "            return  json.loads(generated_text) \n",
    "        # if definition_match and examples_match:\n",
    "        #     return {\n",
    "        #         \"definition\": definition_match.group(1),\n",
    "        #         \"examples\": [examples_match.group(1), examples_match.group(2)]\n",
    "        #     }\n",
    "        \n",
    "        print(\"Aucun JSON valide trouvé dans la réponse\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Erreur API Hugging Face: {response.status_code} -> {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'human being',\n",
       " 'definition': 'A living organism belonging to the species Homo sapiens, characterized by intelligence, consciousness, and the ability to reason and learn through experience.',\n",
       " 'translation': 'être humain',\n",
       " 'example1': 'All human beings have the right to be treated with dignity and respect.',\n",
       " 'example2': 'As human beings, we have a responsibility to protect the environment for future generations.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "word = \"human being\"\n",
    "result = get_definition_and_examples(word)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Définition: A person, as opposed to an animal, plant, or other living thing.\n",
      "Traduction: être humain\n",
      "Exemple 1: As a human being, I have the right to be treated with dignity and respect.\n",
      "Exemple 2: The human being's relationship with nature is complex and multifaceted.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "word = \"human being\"\n",
    "result = get_definition_and_examples(word)\n",
    "if result:\n",
    "    print(\"Définition:\", result[\"definition\"])\n",
    "    print(\"Traduction:\", result[\"translation\"])\n",
    "    print(\"Exemple 1:\", result[\"example1\"])\n",
    "    print(\"Exemple 2:\", result[\"example2\"]) \n",
    "else:\n",
    "    print(\"Impossible d'obtenir la définition et les exemples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import streamlit as st\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Récupère le token Hugging Face depuis les variables d'environnement\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# Initialise le client avec un modèle warm\n",
    "client = InferenceClient(\n",
    "    model=\"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    token=HF_TOKEN  # ou api_key=HF_TOKEN si version plus récente de huggingface_hub\n",
    ")\n",
    "\n",
    "def create_fallback_response(word):\n",
    "    return {\n",
    "        \"word\": word,\n",
    "        \"definition\": \"No definition available.\",\n",
    "        \"translation\": \"Aucune traduction disponible.\",\n",
    "        \"example1\": \"No example available.\",\n",
    "        \"example2\": \"No example available.\"\n",
    "    }\n",
    "\n",
    "def extract_info_manually(text, word):\n",
    "    # Extraction simple si le JSON est mal formé\n",
    "    lines = text.split(\"\\n\")\n",
    "    result = {\"word\": word}\n",
    "    for line in lines:\n",
    "        if \":\" in line:\n",
    "            key, val = line.split(\":\", 1)\n",
    "            result[key.strip().lower()] = val.strip()\n",
    "    return result\n",
    "\n",
    "def get_definition_and_examples(word):\n",
    "    if not HF_TOKEN:\n",
    "        print(\"Token Hugging Face manquant. Veuillez configurer votre clé API.\")\n",
    "        return create_fallback_response(word)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an English assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            f'Provide a definition, French translation, and two English example sentences for the word '\n",
    "            f'\"{word}\". Format as JSON with keys: word, definition, translation, example1, example2.'\n",
    "        )}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "            messages=messages,\n",
    "            max_tokens=300,\n",
    "            temperature=0.1,\n",
    "        )\n",
    "        text = response.choices[0].message.content\n",
    "\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        except json.JSONDecodeError:\n",
    "            return extract_info_manually(text, word)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'appel au modèle : {str(e)}\")\n",
    "        return create_fallback_response(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'huge', 'definition': 'extremely large in size or amount', 'translation': 'énorme', 'example1': 'The huge crowd filled the stadium to capacity.', 'example2': 'She has a huge collection of vintage records.'}\n"
     ]
    }
   ],
   "source": [
    "result = get_definition_and_examples(\"huge\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
